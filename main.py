"""
main.py (v2)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ç¨‹åºå…¥å£ï¼šæ•´åˆäº†é•¿æ–‡æœ¬åˆ†æ®µã€è¿›åº¦å¯è§†åŒ–ã€äººå·¥å®¡æ ¸å¼€å…³

æ–°åŠŸèƒ½ï¼ˆv2ï¼‰ï¼š
  - é•¿æ–‡æœ¬è‡ªåŠ¨åˆ†æ®µï¼šè¶…è¿‡ CHUNK_SIZE å­—ç¬¦çš„è¾“å…¥ä¼šè‡ªåŠ¨åˆ†æ®µå¤„ç†
  - è¿›åº¦å¯è§†åŒ–ï¼šrich ç¾åŒ–è¾“å‡ºï¼Œå±•ç¤ºæ¯ä¸ª Agent çŠ¶æ€å’Œç”¨æ—¶
  - å¤šæ®µåˆå¹¶ï¼šå¤šä¸ª chunk çš„åœºæ™¯ç¼–å·è‡ªåŠ¨åç§»ï¼Œæœ€ç»ˆåˆå¹¶ä¸ºä¸€ä»½å®Œæ•´å‰§æœ¬

ç”¨æ³•ï¼š
    python main.py
    python main.py --input my_novel.txt --type å¤ä»£è¨€æƒ…
    HUMAN_REVIEW=true python main.py      # å¼€å¯äººå·¥å®¡æ ¸
    CHUNK_SIZE=1500 python main.py        # è°ƒå°åˆ†æ®µå¤§å°ï¼ˆæµ‹è¯•ç”¨ï¼‰
"""

import argparse
import json
import os
import sys
from datetime import datetime
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))

from config import (
    SUPPORTED_NOVEL_TYPES,
    MAX_REVISIONS,
    LLM_PROVIDER,
    LLM_MODEL,
    DEBUG,
    HUMAN_REVIEW,
    CHUNK_SIZE,
    CHUNK_OVERLAP,
)
from graph import get_workflow
from state import WorkflowState
from utils.chunker import split_into_chunks, get_chunk_info
from utils.progress import progress


def load_novel_text(filepath: str) -> str:
    path = Path(filepath)
    if not path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ–‡ä»¶: {filepath}")
    return path.read_text(encoding="utf-8")


def validate_env():
    if LLM_PROVIDER == "openai":
        if not os.getenv("OPENAI_API_KEY", ""):
            print("âš ï¸  æœªæ£€æµ‹åˆ° OPENAI_API_KEY")
            print("   export OPENAI_API_KEY=sk-your-key")
            sys.exit(1)
    elif LLM_PROVIDER == "gemini":
        if not os.getenv("GOOGLE_API_KEY", ""):
            print("âš ï¸  æœªæ£€æµ‹åˆ° GOOGLE_API_KEY")
            print("   export GOOGLE_API_KEY=your-key")
            sys.exit(1)


def build_initial_state(novel_text: str, novel_type: str) -> WorkflowState:
    """æ„å»ºå·¥ä½œæµåˆå§‹çŠ¶æ€"""
    return {
        "novel_text": novel_text,
        "novel_type": novel_type,
        "character_sheet": None,
        "screenplay_scenes": [],
        "storyboard_scenes": [],
        "sound_scenes": [],
        "director_feedback": [],
        "revision_target": None,
        "revision_count": 0,
        "skip_human_review": False,
        "human_review_target": "director",
        "is_approved": False,
        "final_script": None,
    }


def run_single_chunk(
    novel_text: str, novel_type: str, scene_offset: int = 0
) -> WorkflowState:
    """
    å¯¹å•ä¸ªæ–‡æœ¬ chunk è¿è¡Œå®Œæ•´çš„å¤šæ™ºèƒ½ä½“å·¥ä½œæµã€‚

    Args:
        novel_text: è¦å¤„ç†çš„æ–‡æœ¬ç‰‡æ®µ
        novel_type: å°è¯´ç±»å‹
        scene_offset: åœºæ™¯ç¼–å·åç§»ï¼ˆå¤šæ®µå¤„ç†æ—¶ä¿è¯ç¼–å·è¿ç»­ï¼‰

    Returns:
        æœ€ç»ˆçš„ WorkflowState
    """
    initial_state = build_initial_state(novel_text, novel_type)
    workflow = get_workflow()
    final_state = workflow.invoke(initial_state)

    # åº”ç”¨åœºæ™¯ç¼–å·åç§»ï¼ˆå¤šæ®µåˆå¹¶æ—¶ä¿è¯è¿ç»­ï¼‰
    if scene_offset > 0:
        for scene_list_key in [
            "screenplay_scenes",
            "storyboard_scenes",
            "sound_scenes",
        ]:
            for scene in final_state.get(scene_list_key, []):
                scene["scene_number"] = scene["scene_number"] + scene_offset

    return final_state


def merge_chunk_results(
    chunk_states: list[WorkflowState], novel_type: str
) -> WorkflowState:
    """
    å°†å¤šä¸ª chunk çš„å·¥ä½œæµçŠ¶æ€åˆå¹¶ä¸ºä¸€ä¸ªå®Œæ•´çŠ¶æ€ï¼Œ
    é‡æ–°ç”Ÿæˆæœ€ç»ˆå‰§æœ¬æ–‡æœ¬ã€‚
    """
    from agents.director import _format_final_script

    merged: WorkflowState = {
        "novel_text": "\n\n".join(s.get("novel_text", "") for s in chunk_states),
        "novel_type": novel_type,
        "character_sheet": chunk_states[0].get("character_sheet")
        if chunk_states
        else None,
        "screenplay_scenes": [],
        "storyboard_scenes": [],
        "sound_scenes": [],
        "director_feedback": [],
        "revision_target": "approved",
        "revision_count": max(s.get("revision_count", 0) for s in chunk_states),
        "skip_human_review": True,
        "human_review_target": "director",
        "is_approved": True,
        "final_script": None,
    }

    for state in chunk_states:
        merged["screenplay_scenes"].extend(state.get("screenplay_scenes", []))
        merged["storyboard_scenes"].extend(state.get("storyboard_scenes", []))
        merged["sound_scenes"].extend(state.get("sound_scenes", []))

    # é‡æ–°ç”Ÿæˆå®Œæ•´å‰§æœ¬
    merged["final_script"] = _format_final_script(merged)
    return merged


def save_results(state: WorkflowState, output_dir: Path) -> Path:
    output_dir.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    script_path = output_dir / f"final_script_{timestamp}.txt"
    script_path.write_text(state.get("final_script", ""), encoding="utf-8")

    raw_data = {
        "novel_type": state.get("novel_type"),
        "character_sheet": state.get("character_sheet"),
        "screenplay_scenes": state.get("screenplay_scenes", []),
        "storyboard_scenes": state.get("storyboard_scenes", []),
        "sound_scenes": state.get("sound_scenes", []),
        "revision_count": state.get("revision_count", 0),
    }
    json_path = output_dir / f"raw_data_{timestamp}.json"
    json_path.write_text(
        json.dumps(raw_data, ensure_ascii=False, indent=2), encoding="utf-8"
    )
    return script_path


def main():
    parser = argparse.ArgumentParser(
        description="ç½‘æ–‡è½¬æ¼«å‰§å‰§æœ¬ Â· å¤šæ™ºèƒ½ä½“å·¥ä½œæµ v2",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    parser.add_argument("--input", "-i", default="sample_input/chapter_1.txt")
    parser.add_argument(
        "--type", "-t", default="ä»™ä¾ /ç„å¹»", choices=SUPPORTED_NOVEL_TYPES
    )
    parser.add_argument("--output", "-o", default="./output")
    parser.add_argument("--no-save", action="store_true")
    args = parser.parse_args()

    validate_env()

    try:
        novel_text = load_novel_text(args.input)
    except FileNotFoundError as e:
        print(f"âŒ {e}")
        sys.exit(1)

    # â”€â”€ åˆ†ææ–‡æœ¬ï¼Œå†³å®šæ˜¯å¦åˆ†æ®µ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    info = get_chunk_info(novel_text, CHUNK_SIZE)
    chunks = split_into_chunks(novel_text, CHUNK_SIZE, CHUNK_OVERLAP)

    # â”€â”€ æ‰“å°å¯åŠ¨æ¨ªå¹… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    progress.print_banner(
        novel_type=args.type,
        novel_chars=info["total_chars"],
        llm_provider=LLM_PROVIDER,
        llm_model=LLM_MODEL,
        chunk_count=len(chunks),
        max_revisions=MAX_REVISIONS,
    )

    if len(chunks) > 1:
        print(
            f"\nğŸ“¦ é•¿æ–‡æœ¬æ¨¡å¼ï¼šæ–‡æœ¬è¢«åˆ†ä¸º {len(chunks)} æ®µï¼ˆæ¯æ®µçº¦ {CHUNK_SIZE} å­—ç¬¦ï¼‰"
        )
        print(f"   å°†ä¾æ¬¡å¤„ç†æ¯æ®µï¼Œæœ€ç»ˆåˆå¹¶ä¸ºå®Œæ•´å‰§æœ¬\n")

    if HUMAN_REVIEW:
        print("ğŸ‘¤ äººå·¥å®¡æ ¸æ¨¡å¼å·²å¼€å¯ï¼ˆç¬¬ä¸€è½®å®Œæˆåä¼šæš‚åœç­‰å¾…ç¡®è®¤ï¼‰\n")

    # â”€â”€ æ‰§è¡Œå·¥ä½œæµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("ğŸš€ å·¥ä½œæµå¯åŠ¨...\n")
    chunk_states = []
    scene_offset = 0

    try:
        for i, chunk in enumerate(chunks):
            if len(chunks) > 1:
                print(f"\n{'â”' * 50}")
                print(
                    f"  â–¶ å¤„ç†ç¬¬ {i + 1}/{len(chunks)} æ®µ  "
                    f"ï¼ˆ{len(chunk)} å­—ç¬¦ï¼Œåœºæ™¯ä» {scene_offset + 1} å¼€å§‹ï¼‰"
                )
                print(f"{'â”' * 50}")

            state = run_single_chunk(chunk, args.type, scene_offset)
            chunk_states.append(state)

            # æ›´æ–°ä¸‹ä¸€æ®µçš„åœºæ™¯åç§»
            scene_count = len(state.get("screenplay_scenes", []))
            scene_offset += scene_count

    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ å·¥ä½œæµæ‰§è¡Œå‡ºé”™: {type(e).__name__}: {e}")
        if DEBUG:
            import traceback

            traceback.print_exc()
        sys.exit(1)

    # â”€â”€ åˆå¹¶å¤šæ®µç»“æœï¼ˆæˆ–ç›´æ¥ä½¿ç”¨å•æ®µç»“æœï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if len(chunk_states) == 1:
        final_state = chunk_states[0]
    else:
        print(f"\nğŸ”— åˆå¹¶ {len(chunks)} æ®µç»“æœ...")
        final_state = merge_chunk_results(chunk_states, args.type)

    total_scenes = len(final_state.get("screenplay_scenes", []))
    total_revisions = final_state.get("revision_count", 0)

    # â”€â”€ æ‰“å°æ±‡æ€» â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    chars = (final_state.get("character_sheet") or {}).get("main_characters", [])
    char_names = "ã€".join(c.get("name", "?") for c in chars) if chars else "æ— "
    print(f"\n{'=' * 55}")
    print(f"  âœ… å·¥ä½œæµå®Œæˆ")
    print(f"  ğŸ“š è¯†åˆ«è§’è‰²ï¼š{char_names}")
    print(f"  ğŸ“ æ€»åœºæ™¯æ•°ï¼š{total_scenes}")
    print(f"  ğŸ”„ å®¡æ ¸è½®æ¬¡ï¼š{total_revisions}")

    # â”€â”€ æ‰“å°æœ€ç»ˆå‰§æœ¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print()
    print(final_state.get("final_script", "ï¼ˆæ— è¾“å‡ºï¼‰"))

    # â”€â”€ ä¿å­˜æ–‡ä»¶ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if not args.no_save:
        script_path = save_results(final_state, Path(args.output))
        print(f"\nğŸ“„ æœ€ç»ˆå‰§æœ¬ï¼š{script_path}")
        print(f"ğŸ“Š åŸå§‹æ•°æ®ï¼š{Path(args.output) / 'raw_data_*.json'}")


if __name__ == "__main__":
    main()
